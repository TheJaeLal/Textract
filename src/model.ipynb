{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import layers\n",
    "from config import vocab_size, img_width,img_height, alpha\n",
    "from Arch import CNN, BRNN, FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Global Debugging flag..\n",
    "debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolution_Output_size:(5,29)\n",
      "LSTM_Output_size:(Tensor(\"bidirectional_rnn/fw/fw/transpose_1:0\", shape=(?, 145, 256), dtype=float32),Tensor(\"ReverseV2:0\", shape=(?, 145, 256), dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "# with tf.device('/gpu:0'):\n",
    "\n",
    "#Model\n",
    "#----------------------------------------------------------------------------#\n",
    "\n",
    "wconv,bconv,wfc,bfc = layers.init_weights(CNN,FC)\n",
    "\n",
    "dropout_conv = tf.placeholder(tf.float32,shape=[])\n",
    "dropout_lstm = tf.placeholder(tf.float32,shape=[])\n",
    "dropout_fc = tf.placeholder(tf.float32,shape=[])\n",
    "\n",
    "#Input 'Image'\n",
    "inputs = tf.placeholder(tf.float32,shape=[None,img_height,img_width])\n",
    "\n",
    "X = tf.reshape(inputs,(-1,img_height,img_width,1))\n",
    "\n",
    "#-------------------Convolution-----------------------#\n",
    "\n",
    "conv = [None] * len(CNN)\n",
    "\n",
    "#Create your CNN\n",
    "for i in range(len(CNN)):\n",
    "    strides = CNN[i]['conv'][1]\n",
    "    conv[i] = layers.conv(X,wconv[i],bconv[i],strides,CNN[i]['activate'],dropout_conv)\n",
    "    \n",
    "    if CNN[i]['pool']:\n",
    "        conv[i] = layers.max_pool(conv[i],CNN[i]['pool'])\n",
    "    \n",
    "    #Input to next layer is output of previous layer...\n",
    "    X = conv[i]\n",
    "    \n",
    "#--------All right upto here------------#\n",
    "\n",
    "#Calculate height and width of output from CNN\n",
    "conv_out_height,conv_out_width = layers.calc_out_dims(CNN,img_height,img_width)\n",
    "if debug:\n",
    "    print('Convolution_Output_size:({},{})'.format(conv_out_height,conv_out_width))\n",
    "\n",
    "#----------------LSTM--------------------------#\n",
    "#Treat a single pixel from each filter or feature map as an individual feature\n",
    "#So number of features  = num_conv4 filters or feature maps\n",
    "#length_of_sequence = width * height of the output from conv3 \n",
    "\n",
    "filters_in_last_conv = CNN[-1]['conv'][2]\n",
    "lstm_inputs = tf.reshape(conv[-1],(-1,conv_out_height*conv_out_width,filters_in_last_conv))\n",
    "\n",
    "#Number of time_steps to unroll for..\n",
    "seq_len = conv_out_height * conv_out_width\n",
    "\n",
    "#So that we can use different batch size during testing...\n",
    "time_steps = tf.placeholder(tf.int32,shape = [None])\n",
    "targets = tf.sparse_placeholder(tf.int32,name='targets')\n",
    "\n",
    "lstm_initializer = tf.contrib.layers.xavier_initializer()\n",
    "fw_layer = layers.lstm(BRNN['layers'],BRNN['hidden_units'],lstm_initializer,dropout=dropout_lstm)\n",
    "bw_layer = layers.lstm(BRNN['layers'],BRNN['hidden_units'],lstm_initializer,dropout=dropout_lstm)\n",
    "(outputs_fw,outputs_bw),_ = tf.nn.bidirectional_dynamic_rnn(fw_layer,bw_layer,lstm_inputs,dtype=tf.float32)\n",
    "\n",
    "# outputs,_,_ = tf.contrib.rnn.stack_bidirectional_dynamic_rnn(cells_fw,cells_bw,inputs = lstm_inputs,dtype=tf.float32)\n",
    "if debug:\n",
    "    print('LSTM_Output_size:({},{})'.format(outputs_fw,outputs_bw))\n",
    "\n",
    "#Concatenate the output from both cells (forward and backward)\n",
    "blstm_outputs = tf.concat([outputs_fw,outputs_bw], 2)\n",
    "\n",
    "#flatten out all except the last dimension\n",
    "fc_inputs  = tf.reshape(blstm_outputs,[-1,2*BRNN['hidden_units']])\n",
    "\n",
    "#Feed into the fully connected layer\n",
    "#No activation cuz, the output of this layer is feeded into CTC Layer as logits\n",
    "for i in range(len(wfc)):\n",
    "    fc_out = layers.fc(fc_inputs,wfc[i],bfc[i],activation=None,dropout=dropout_fc)\n",
    "    #Input to next layer is output of previous layer..\n",
    "    fc_inputs = fc_out\n",
    "\n",
    "#Reshape back to batch_size, seq_len,vocab_size\n",
    "logits = tf.reshape(fc_out,[-1,seq_len,vocab_size])\n",
    "\n",
    "#convert them to time major\n",
    "logits = tf.transpose(logits,[1,0,2])\n",
    "\n",
    "#Calculate loss\n",
    "loss = tf.nn.ctc_loss(targets, logits, time_steps)\n",
    "cost = tf.reduce_mean(loss)\n",
    "\n",
    "#Optimize\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=alpha)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# CTC decoder.\n",
    "decoded, log_prob = tf.nn.ctc_greedy_decoder(logits, time_steps)\n",
    "label_error_rate = tf.reduce_mean(tf.edit_distance(tf.cast(decoded[0], tf.int32),targets))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
