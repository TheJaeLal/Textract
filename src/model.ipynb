{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(CNN,FC): \n",
    "    \n",
    "    #Weights Initializer\n",
    "    fc_initializer = tf.contrib.layers.xavier_initializer()\n",
    "    conv_initializer = tf.contrib.layers.xavier_initializer_conv2d()\n",
    "    \n",
    "    wconv_shapes = [] ; bconv_shape = []\n",
    "    wfc_shapes = []; bfc_shapes = []\n",
    "    \n",
    "    #All theses params are created and returned...\n",
    "    wconv = [] ; bconv = []\n",
    "    wfc = [] ; bfc = []\n",
    "    \n",
    "    #Setup the conv_filter shapes\n",
    "    for i in range(len(CNN)):\n",
    "        # i goes from 0 to 4\n",
    "        # i+1 goes from 1 to 5\n",
    "\n",
    "        filter_size = CNN[i]['conv'][0]\n",
    "\n",
    "        if i == 0:\n",
    "            #Number of input channels = 1 in 1st conv layer\n",
    "            ch_in = 1\n",
    "        else:\n",
    "            #Output channels/filters of the previous layer..\n",
    "            ch_in = CNN[i-1]['conv'][2]\n",
    "            \n",
    "        #Number of output_channels/filters\n",
    "        ch_out = CNN[i]['conv'][2]\n",
    "        \n",
    "        wconv_shapes.append([filter_size,filter_size,ch_in,ch_out])\n",
    "        \n",
    "    #Setup Fully connected weight shapes..\n",
    "    for i in range(1,len(FC)):\n",
    "        wfc_shapes.append([fc_units[i-1],fc_units[i]])\n",
    "        bfc_shapes.append([fc_units[i]])\n",
    "\n",
    "    #Create Weights and Biases\n",
    "    for i in range(len(wconv)):\n",
    "        wconv[i] = tf.Variable(conv_initializer(wconv_shape[i]))\n",
    "        bconv[i] = tf.Variable(tf.zeros(bconv_shape)) \n",
    "   \n",
    "    for i in range(len(wfc)):\n",
    "        wfc[i] = tf.Variable(fc_initializer(wfc_shape[i]))\n",
    "        bfc[i] = tf.Variable(tf.zeros(bfc_shape[i]))\n",
    "\n",
    "    return wconv,bconv,wfc,bfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global Debugging flag..\n",
    "debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Format: 'conv':[filter_size,strides,num_filters], 'pool':[strides]\n",
    "\n",
    "#Model Params\n",
    "CNN = [\n",
    "        {'conv':[3,1,25], 'activate':'relu', 'pool':2},\n",
    "        {'conv':[3,1,50], 'activate':'relu', 'pool':2},\n",
    "        {'conv':[3,1,100], 'activate':'relu', 'pool':2},\n",
    "        {'conv':[3,1,200], 'activate':'relu', 'pool':3},\n",
    "        {'conv':[3,1,400], 'activate':'relu' ,'pool':None},\n",
    "]\n",
    "\n",
    "BRNN = {\n",
    "        'layers':5,\n",
    "        'hidden_units':256,\n",
    "}\n",
    "\n",
    "FC = [\n",
    "        {'units':2*BRNN['hidden_units'],'activate':None},\n",
    "        {'units':2*vocab_size,'activate':None},\n",
    "        {'units':vocab_size,'activate':None},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.device('/gpu:0'):\n",
    "\n",
    "#Model\n",
    "#----------------------------------------------------------------------------#\n",
    "\n",
    "wconv,bconv,wfc,bfc = init_weights(CNN,FC)\n",
    "\n",
    "dropout_conv = tf.placeholder(tf.float32,shape=[])\n",
    "dropout_lstm = tf.placeholder(tf.float32,shape=[])\n",
    "dropout_fc = tf.placeholder(tf.float32,shape=[])\n",
    "\n",
    "#Input 'Image'\n",
    "inputs = tf.placeholder(tf.float32,shape=[None,img_height,img_width])\n",
    "\n",
    "X = tf.reshape(inputs,(-1,img_height,img_width,1))\n",
    "\n",
    "#-------------------Convolution-----------------------#\n",
    "\n",
    "conv = [None] * len(CNN)\n",
    "\n",
    "for i in range(len(CNN)):\n",
    "    conv[i] = conv_layer(X,wconv[i],bconv[i],sconv[i],CNN[i]['activate'],dropout_conv)\n",
    "    \n",
    "    if CNN[i]['pool']:\n",
    "        conv[i] = max_pool(conv[i],CNN[i]['pool'])\n",
    "\n",
    "#--------All right upto here------------#\n",
    "\n",
    "#Calculate height and width of output from CNN\n",
    "conv_out_height,conv_out_width = calc_out_dims(CNN,img_height,img_width)\n",
    "print('Convolution_Output_size:({},{})'.format(conv_out_height,conv_out_width))\n",
    "\n",
    "#----------------LSTM--------------------------#\n",
    "#Treat a single pixel from each filter or feature map as an individual feature\n",
    "#So number of features  = num_conv4 filters or feature maps\n",
    "#length_of_sequence = width * height of the output from conv3 \n",
    "\n",
    "filters_in_last_conv = CNN[-1]['conv'][2]\n",
    "lstm_inputs = tf.reshape(conv[-1],(-1,conv_out_height*conv_out_width,filters_in_last_conv))\n",
    "\n",
    "#Number of time_steps to unroll for..\n",
    "seq_len = conv_out_height * conv_out_width\n",
    "\n",
    "#So that we can use different batch size during testing...\n",
    "time_steps = tf.placeholder(tf.int32,shape = [None])\n",
    "targets = tf.sparse_placeholder(tf.int32,name='targets')\n",
    "\n",
    "lstm_initializer = tf.contrib.layers.xavier_initializer()\n",
    "fw_layer = lstm_layer(BRNN['layers'],BRNN['hidden_units'],lstm_initializer,dropout=dropout_lstm)\n",
    "bw_layer = lstm_layer(BRNN['layers'],BRNN['hidden_units'],lstm_initializer,dropout=dropout_lstm)\n",
    "(outputs_fw,outputs_bw),_ = tf.nn.bidirectional_dynamic_rnn(fw_layer,bw_layer,lstm_inputs,dtype=tf.float32)\n",
    "\n",
    "# outputs,_,_ = tf.contrib.rnn.stack_bidirectional_dynamic_rnn(cells_fw,cells_bw,inputs = lstm_inputs,dtype=tf.float32)\n",
    "\n",
    "print('LSTM_Output_size:({},{})'.format(outputs_fw,outputs_bw))\n",
    "\n",
    "#Concatenate the output from both cells (forward and backward)\n",
    "blstm_outputs = tf.concat([outputs_fw,outputs_bw], 2)\n",
    "\n",
    "#flatten out all except the last dimension\n",
    "fc_inputs  = tf.reshape(blstm_outputs,[-1,2*rnn_hidden_units])\n",
    "\n",
    "#Feed into the fully connected layer\n",
    "#No activation cuz, the output of this layer is feeded into CTC Layer as logits\n",
    "fc_outputs_1 = fc_layer(fc_inputs,wfc1,bfc1,activation=None,dropout=dropout_fc)\n",
    "fc_outputs_2 = fc_layer(fc_outputs_1,wfc2,bfc2,activation=None,dropout=dropout_fc)\n",
    "\n",
    "#Reshape back to batch_size, seq_len,vocab_size\n",
    "logits = tf.reshape(fc_outputs_2,[-1,seq_len,vocab_size])\n",
    "\n",
    "#convert them to time major\n",
    "logits = tf.transpose(logits,[1,0,2])\n",
    "\n",
    "#Calculate loss\n",
    "loss = tf.nn.ctc_loss(targets, logits, time_steps)\n",
    "cost = tf.reduce_mean(loss)\n",
    "\n",
    "#Optimize\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=alpha)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# CTC decoder.\n",
    "decoded, log_prob = tf.nn.ctc_greedy_decoder(logits, time_steps)\n",
    "label_error_rate = tf.reduce_mean(tf.edit_distance(tf.cast(decoded[0], tf.int32),targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(x,w,b,s,activation=None,dropout=1.0):\n",
    "    conv = tf.nn.conv2d(input=x,filter=w,padding='SAME',strides=[1,s,s,1]) + b\n",
    "    \n",
    "    if activation == 'relu':\n",
    "        conv = tf.nn.relu(conv)\n",
    "    \n",
    "    elif activation == 'leaky_relu':\n",
    "        conv = tf.nn.leaky_relu(conv)\n",
    "        \n",
    "    elif activation == 'elu':\n",
    "        conv = tf.nn.elu(conv)\n",
    "        \n",
    "    elif activation == 'tanh':\n",
    "        conv = tf.nn.tanh(conv)\n",
    "        \n",
    "    conv = tf.nn.dropout(conv,dropout)\n",
    "    \n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_layer(x,w,b,activation=None,dropout=1.0):\n",
    "    \n",
    "    out = tf.matmul(x,w) + b\n",
    "    \n",
    "    if activation == 'relu':\n",
    "        out = tf.nn.relu(out)\n",
    "    \n",
    "    elif activation == 'leaky_relu':\n",
    "        out = tf.nn.leaky_relu(out)\n",
    "    \n",
    "    elif activation == 'elu':\n",
    "        out = tf.nn.elu(out)\n",
    "        \n",
    "    elif activation == 'tanh':\n",
    "        out = tf.nn.elu(out)\n",
    "        \n",
    "    out = tf.nn.dropout(out,dropout)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_layer(num_layers,hidden_units,initializer,dropout=1.0):\n",
    "    \n",
    "    cells = []\n",
    "    for _ in range(num_layers):\n",
    "        cell = tf.contrib.rnn.LSTMCell(hidden_units,initializer=initializer)\n",
    "        cell = tf.contrib.rnn.DropoutWrapper(cell,output_keep_prob=dropout,dtype=tf.float32)\n",
    "        cells.append(cell)\n",
    "    \n",
    "    layer = tf.contrib.rnn.MultiRNNCell(cells)\n",
    "    \n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool(x,s):\n",
    "    \n",
    "    pool = tf.nn.max_pool(x,ksize=[1,s,s,1],strides=[1,s,s,1],padding='SAME')\n",
    "    \n",
    "    return pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_out_dims(CNN,height,width):\n",
    "    for i in range(len(CNN)):\n",
    "\n",
    "        strides = CNN[i]['conv'][1]\n",
    "\n",
    "        height = ceil(float(height) / float(strides))\n",
    "        width = ceil(float(width) / float(strides))\n",
    "\n",
    "        if CNN[i]['pool']:\n",
    "            height = ceil(float(height) / float(CNN[i]['pool']))\n",
    "            width = ceil(float(width) / float(CNN[i]['pool']))    \n",
    "    \n",
    "    return height,width"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
