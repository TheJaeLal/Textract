{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import shelve\n",
    "import joblib\n",
    "from math import ceil\n",
    "import time\n",
    "import model\n",
    "from Augment import valid_datagen\n",
    "import helper\n",
    "from test_config import vocabulary,test_batch_size,resume_epoch,model_dir\n",
    "from Arch import CNN\n",
    "import layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test Labels and Image-Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mount_point = '../'\n",
    "\n",
    "with shelve.open(mount_point+'IAM_Data','c') as shelf:\n",
    "    test_label = shelf['test_label']\n",
    "    \n",
    "test_array = joblib.load(mount_point+'data/test_array')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph,dropout_lstm,dropout_fc,inputs,time_steps,targets,loss,train,decoded,label_error_rate,seq_len,is_training,conv_dropout,gradients,interim_dropout = model.model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = valid_datagen.flow(test_array,test_label,test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_samples = test_array.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches = int(ceil(num_test_samples/test_batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(graph = graph) as sess:\n",
    "    \n",
    "    saver = tf.train.Saver(max_to_keep=None)\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    checkpoint = False\n",
    "\n",
    "    timer  = 0\n",
    "    \n",
    "    #Resume training from resume_epoch\n",
    "    if resume_epoch != 0:\n",
    "        saver.restore(sess, mount_point+model_dir+'/cnn_lstm_fc_'+str(resume_epoch))\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    test_loss,ler = 0.0,0.0\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for xt, yt in test_generator: \n",
    "\n",
    "        if count == num_batches:\n",
    "            break\n",
    "\n",
    "        yt,widths = np.hsplit(yt,2)\n",
    "\n",
    "        widths = np.squeeze(widths,axis=1)\n",
    "        yt = np.squeeze(yt,axis=1)\n",
    "\n",
    "        widths = [layers.calc_out_dims(CNN,0,int(width))[1] for width in widths]\n",
    "        widths = np.array(widths)\n",
    "\n",
    "        test_size = xt.shape[0]\n",
    "        sparse_targets = helper._batch_y(yt,vocabulary)\n",
    "\n",
    "        feed_test = {\n",
    "                     inputs:xt,targets:sparse_targets,\n",
    "                     time_steps:widths,\n",
    "                     conv_dropout:[1]*len(CNN),dropout_fc:1,dropout_lstm:1,\n",
    "                     interim_dropout:1,is_training:False\n",
    "            }\n",
    "\n",
    "        t_loss_val, t_ler= sess.run([loss,label_error_rate],feed_dict = feed_test)\n",
    "\n",
    "        test_loss += t_loss_val\n",
    "        ler += t_ler\n",
    "        count+=1\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    ler /= num_batches\n",
    "\n",
    "    end_time = time.time()\n",
    "    time_taken = end_time - start_time\n",
    "\n",
    "    print(\"Test_loss:{:.2f}, Accuracy:{:.6f}, {:.2f} sec.\\n\".format(test_loss,(1-ler)*100.0,time_taken))\n",
    "        \n",
    "    with open('progress.csv','a') as f:\n",
    "        f.write(\"Test_loss:{:.2f}, Accuracy:{:.6f}, {:.2f} sec.\\n\".format(test_loss,(1-ler)*100.0,time_taken))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict using Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resume_epoch = 1545"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.Session() as sess:\n",
    "#     # Load the graph\n",
    "#     saver = tf.train.import_meta_graph('../model/200_5_Lines_RNN_'+str(resume_epoch)+'.meta')\n",
    "#     # Restore the weights and biases\n",
    "#     saver.restore(sess, '../model/200_5_Lines_RNN_'+str(resume_epoch))\n",
    "\n",
    "#     #Extract the placeholders\n",
    "#     inputs = sess.graph.get_tensor_by_name('Placeholder:0')\n",
    "#     target_indices = sess.graph.get_tensor_by_name('targets/indices:0')\n",
    "#     target_values = sess.graph.get_tensor_by_name('targets/values:0')\n",
    "#     target_shape = sess.graph.get_tensor_by_name('targets/shape:0')\n",
    "    \n",
    "#     time_steps = sess.graph.get_tensor_by_name('Placeholder_1:0')\n",
    "#     dropout_lstm = sess.graph.get_tensor_by_name('Placeholder_2:0')\n",
    "#     dropout_fc = sess.graph.get_tensor_by_name('Placeholder_3:0')\n",
    "    \n",
    "#     decoded = sess.graph.get_tensor_by_name('CTCGreedyDecoder:1')\n",
    "#     cost = sess.graph.get_tensor_by_name('Mean:0')\n",
    "#     label_error_rate = sess.graph.get_tensor_by_name('Mean_1:0')\n",
    "\n",
    "#     start_time = time.time()\n",
    "    \n",
    "    \n",
    "#     for b in range(len(batches_x)):\n",
    "#         feed = {inputs:batches_x[b].transpose([2,0,1]),target_indices:batches_y[b][0],target_values:batches_y[b][1],target_shape:batches_y[b][2],\n",
    "#                 time_steps:np.array([seq_len]*batch_size),dropout_lstm:1.0, dropout_fc:1.0,\n",
    "#                }\n",
    "\n",
    "#         cost_val,ler_val,d = sess.run([cost,label_error_rate,decoded], feed_dict=feed)\n",
    "\n",
    "#         outputs.append(d)\n",
    "\n",
    "#         end_time = time.time()   \n",
    "    \n",
    "#         time_taken = end_time - start_time\n",
    "\n",
    "# #         print(\"{:.6f},{:.2f},{:.2f}\\n\".format(cost_val,ler_val,time_taken))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imsave('1.png',image_arrays[training_list[0]],cmap='gray',format='png')\n",
    "# plt.imsave('2.png',image_arrays[training_list[1]],cmap='gray',format='png')\n",
    "# plt.imsave('3.png',image_arrays[training_list[2]],cmap='gray',format='png')\n",
    "# # plt.imsave('4.png',image_arrays[training_list[3]],cmap='gray',format='png')\n",
    "# # plt.imsave('5.png',image_arrays[training_list[4]],cmap='gray',format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# content = \"\".join([vocabulary[char] for char in outputs[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = \"\".join(image_labels[training_list[i]] for i in range(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(image_labels[training_list[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(batches_x[0].transpose([2,0,1])[0],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = str(list(map(dct.get, list(prob_d.values))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Evaluate the Output\n",
    "# content = []\n",
    "# for k in range(len(out1)):\n",
    "#     content.append(''.join([vocabulary[x] for x in out1[k]]))\n",
    "#     print(\"\\n\".join(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabulary[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out1[0]\n",
    "# for x in out1[0]:\n",
    "#     print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out1[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Outputs...\n",
    "# Output of CTCGreedyDecoder\n",
    "# [<tf.Tensor 'CTCGreedyDecoder:0' shape=(?, 2) dtype=int64>,\n",
    "#  <tf.Tensor 'CTCGreedyDecoder:1' shape=(?,) dtype=int64>,\n",
    "#  <tf.Tensor 'CTCGreedyDecoder:2' shape=(2,) dtype=int64>,\n",
    "#  <tf.Tensor 'CTCGreedyDecoder:3' shape=(32, 1) dtype=float32>]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
