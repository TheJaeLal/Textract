{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "from helper import create_batches\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import shelve\n",
    "import joblib\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "\n",
    "#Cuz the file is inside 'code' directory\n",
    "mount_point = \"../shelved_data/\"\n",
    "\n",
    "with shelve.open(mount_point+'IAM_Data') as shelf:\n",
    "    vocabulary = shelf['chars']\n",
    "    list_of_images = shelf['list_of_images']\n",
    "    image_labels = shelf['image_labels']\n",
    "    \n",
    "image_arrays = joblib.load(mount_point+'image_arrays')\n",
    "\n",
    "# #List_images ko sort karo\n",
    "# list_of_images.sort()\n",
    "\n",
    "#Convert vocabulary to list\n",
    "vocabulary = list(vocabulary)\n",
    "#Sort so as to have the same ordering every time..\n",
    "vocabulary.sort()\n",
    "vocabulary.append(\"<Blank>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model parameters\n",
    "img_height = 104\n",
    "img_width = 688\n",
    "vocab_size = len(vocabulary)\n",
    "\n",
    "#Common Hyper Parameters\n",
    "epochs = 500\n",
    "#Should be proportional to the number of Images\n",
    "#should be a multiple of 13000\n",
    "batch_size = 200 \n",
    "\n",
    "#LSTM Params\n",
    "rnn_hidden_units = 200\n",
    "rnn_layers = 5\n",
    "\n",
    "conv_out_height, conv_out_width = (int(math.ceil(img_height/(2**3 * 3))),int(math.ceil(img_width/(2**3 * 3))))\n",
    "\n",
    "#Number of time_steps to unroll for..\n",
    "seq_len = conv_out_height * conv_out_width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save my MoDel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Separate Training, testing and validation images into different lists..\n",
    "random.shuffle(list_of_images)\n",
    "train_size = 13000\n",
    "test_size = 1000\n",
    "valid_size = 94\n",
    "\n",
    "training_list = list_of_images[:train_size]\n",
    "testing_list = list_of_images[train_size:train_size+test_size]\n",
    "validation_list = list_of_images[train_size+test_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batches_x,test_batches_y = create_batches(len(testing_list),testing_list,image_arrays,image_labels,vocabulary)\n",
    "valid_batches_x,valid_batches_y = create_batches(len(validation_list),validation_list,image_arrays,image_labels,vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict using Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_epoch = 390"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../model/200_5_Lines_RNN_320\n",
      "320,117.536722,0.66,0.71,97.09253597259521\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_320 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "321,111.007619,0.66,0.67,91.89549040794373\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_321 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "322,109.190777,0.65,0.72,92.2608163356781\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_322 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "323,107.787246,0.65,0.69,91.666024684906\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_323 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "324,106.981319,0.65,0.73,91.90571308135986\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_324 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "325,106.315491,0.64,0.68,91.3876326084137\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_325 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "326,105.597002,0.64,0.72,93.65916419029236\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_326 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "327,105.198649,0.64,0.72,93.67328524589539\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_327 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "328,104.923304,0.64,0.68,90.58012342453003\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_328 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "329,104.532100,0.64,0.67,90.27126789093018\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_329 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "330,104.204927,0.64,0.73,90.20125579833984\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_330 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "331,103.887458,0.63,0.71,90.63933205604553\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_331 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "332,103.636890,0.63,0.70,90.3883101940155\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_332 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "333,103.387089,0.63,0.71,90.54084634780884\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_333 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "334,103.140987,0.63,0.73,93.71886587142944\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_334 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "335,102.929540,0.63,0.70,90.63912749290466\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_335 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "336,102.764596,0.63,0.69,90.16198110580444\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_336 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "337,102.609558,0.63,0.71,90.33583617210388\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_337 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "338,102.260477,0.63,0.70,90.07068014144897\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_338 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "339,102.029143,0.63,0.72,89.89644026756287\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_339 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "340,101.900071,0.63,0.67,92.13898038864136\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_340 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "341,101.737217,0.62,0.70,90.28012013435364\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_341 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "342,101.530816,0.62,0.71,90.8394079208374\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_342 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "343,101.489832,0.62,0.68,88.9916307926178\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_343 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "344,101.164898,0.62,0.69,91.24294137954712\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_344 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "345,101.005710,0.62,0.68,89.28660154342651\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_345 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "346,100.890101,0.62,0.72,88.55826330184937\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_346 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "347,100.673243,0.62,0.70,88.45069098472595\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_347 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "348,100.695982,0.62,0.68,88.76474690437317\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_348 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "349,100.467952,0.62,0.68,88.8581964969635\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_349 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "350,100.290540,0.62,0.70,88.35220766067505\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_350 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "351,100.131176,0.62,0.71,91.1951379776001\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_351 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "352,99.989361,0.62,0.69,88.4732894897461\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_352 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "353,99.894504,0.62,0.71,88.80929732322693\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_353 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "354,99.589794,0.61,0.70,88.21374201774597\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_354 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "355,99.580945,0.61,0.68,88.77464866638184\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_355 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "356,99.517332,0.61,0.68,88.46227717399597\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_356 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "357,99.252725,0.61,0.70,91.22880125045776\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_357 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "358,99.117919,0.61,0.67,88.72506856918335\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_358 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "359,98.867378,0.61,0.70,91.45574712753296\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_359 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "360,98.740554,0.61,0.67,88.1846776008606\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_360 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "361,98.657107,0.61,0.69,88.74786615371704\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_361 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "362,98.449787,0.61,0.69,88.5928168296814\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_362 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "363,98.455304,0.61,0.69,88.413578748703\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_363 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "364,98.191328,0.61,0.71,88.22335410118103\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_364 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "365,98.159634,0.61,0.68,88.67501878738403\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_365 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "366,97.974858,0.61,0.71,88.91050267219543\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_366 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "367,97.999628,0.61,0.68,88.5761981010437\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_367 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "368,97.715126,0.61,0.67,88.42157316207886\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_368 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "369,97.662213,0.61,0.71,88.92981791496277\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_369 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "370,97.543381,0.60,0.70,88.68266868591309\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_370 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "371,97.438745,0.60,0.67,88.782142162323\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_371 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "372,97.291526,0.60,0.70,90.24611973762512\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_372 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "373,97.109151,0.60,0.70,88.6725697517395\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_373 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "374,97.044402,0.60,0.67,88.11920285224915\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_374 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "375,96.827958,0.60,0.71,88.81801867485046\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_375 is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376,96.650173,0.60,0.68,88.38164591789246\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_376 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "377,96.526900,0.60,0.70,88.65398907661438\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_377 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "378,96.484034,0.60,0.69,88.3535304069519\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_378 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "379,96.413939,0.60,0.68,89.0223228931427\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_379 is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Load the graph\n",
    "    saver = tf.train.import_meta_graph('../model/200_5_Lines_RNN_'+str(resume_epoch)+'.meta')\n",
    "\n",
    "    # Restore the weights and biases\n",
    "    saver.restore(sess, '../model/200_5_Lines_RNN_'+str(resume_epoch))\n",
    "\n",
    "    inputs = sess.graph.get_tensor_by_name('Placeholder:0')\n",
    "    \n",
    "    target_indices = sess.graph.get_tensor_by_name('targets/indices:0')\n",
    "    target_values = sess.graph.get_tensor_by_name('targets/values:0')\n",
    "    target_shape = sess.graph.get_tensor_by_name('targets/shape:0')\n",
    "\n",
    "    time_steps = sess.graph.get_tensor_by_name('Placeholder_1:0')\n",
    "    dropout_lstm = sess.graph.get_tensor_by_name('Placeholder_2:0')\n",
    "    dropout_fc = sess.graph.get_tensor_by_name('Placeholder_3:0')\n",
    "    \n",
    "        \n",
    "    train = sess.graph.get_operation_by_name('RMSProp')\n",
    "    cost = sess.graph.get_tensor_by_name('Mean:0')\n",
    "    label_error_rate = sess.graph.get_tensor_by_name('Mean_1:0')\n",
    "    \n",
    "\n",
    "    #checkpoint flag\n",
    "    checkpoint = False\n",
    "    \n",
    "    timer = 0\n",
    "    \n",
    "    for e in range(resume_epoch,epochs): \n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        #Shuffle the training_list\n",
    "        random.shuffle(training_list)\n",
    "        \n",
    "        #Create new training_batches..\n",
    "        train_batches_x,train_batches_y = create_batches(batch_size,training_list,image_arrays,image_labels,vocabulary)\n",
    "    \n",
    "        #Checkpoint every 2 epochs\n",
    "        if (e%1)==0:\n",
    "            checkpoint = True\n",
    "        \n",
    "        total_cost = 0.0\n",
    "        total_ler = 0.0\n",
    "        #Iterate through all images in a single epoch...\n",
    "        for b in range(len(train_batches_x)):\n",
    "            \n",
    "            feed_train = {\n",
    "                    inputs:train_batches_x[b].transpose([2,0,1]),\n",
    "                    target_indices:train_batches_y[b][0],target_values:train_batches_y[b][1],target_shape:train_batches_y[b][2],\n",
    "                    time_steps:np.array([seq_len]*batch_size),\n",
    "                    dropout_fc:np.array(0.9),dropout_lstm:np.array(0.90)\n",
    "                   }\n",
    "        \n",
    "            _,cost_val,train_ler_val = sess.run([train,cost,label_error_rate],feed_dict=feed_train)\n",
    "\n",
    "            total_cost+=cost_val\n",
    "            total_ler+=train_ler_val\n",
    "\n",
    "#         if checkpoint:\n",
    "#             last_cost,train_ler = sess.run([cost,label_error_rate],feed_dict=feed_train)\n",
    "\n",
    "        avg_cost = total_cost/len(train_batches_x) \n",
    "        avg_ler = total_ler/len(train_batches_x)\n",
    "        \n",
    "        #After iterating through all batches..\n",
    "        valid_batch_size = len(validation_list)\n",
    "\n",
    "      \n",
    "        feed_valid = {\n",
    "            inputs:valid_batches_x[0].transpose([2,0,1]),\n",
    "            target_indices:valid_batches_y[0][0],target_values:valid_batches_y[0][1],target_shape:valid_batches_y[0][2],\n",
    "            time_steps:np.array([seq_len]*valid_batch_size),\n",
    "            dropout_fc:np.array(1.0),dropout_lstm:np.array(1.0)\n",
    "           }\n",
    "            \n",
    "        #After iterating through all batches..\n",
    "        test_batch_size = len(testing_list)\n",
    "      \n",
    "        feed_test = {\n",
    "            inputs:test_batches_x[0].transpose([2,0,1]),\n",
    "            target_indices:test_batches_y[0][0],target_values:test_batches_y[0][1],target_shape:test_batches_y[0][2],\n",
    "            time_steps:np.array([seq_len]*test_batch_size),\n",
    "            dropout_fc:np.array(1.0),dropout_lstm:np.array(1.0)\n",
    "           }\n",
    "            \n",
    "\n",
    "       #Evaluate the model, and store every 5 epochs...\n",
    "        if checkpoint:\n",
    "            #Accuracy on valid_data\n",
    "            test_ler = sess.run(label_error_rate,feed_dict=feed_valid)                \n",
    "\n",
    "            end_time = time.time()       \n",
    "            time_taken = end_time - start_time\n",
    "            timer += time_taken\n",
    "     \n",
    "            print(\"{},{:.6f},{:.2f},{:.2f},{}\\n\".format(e,avg_cost,avg_ler,test_ler,timer))\n",
    "\n",
    "            with open('progress.csv','a') as f:\n",
    "                f.write(\"{},{:.6f},{:.2f},{:.2f},{}\\n\".format(e,avg_cost,avg_ler,test_ler,timer))\n",
    "\n",
    "            #Save the model\n",
    "            saver.save(sess,'../model/200_5_Lines_RNN_'+str(e))\n",
    "\n",
    "            #Reset the checkpoint-flag and timer\n",
    "            checkpoint = False\n",
    "            timer = 0\n",
    "        \n",
    "        else:\n",
    "            end_time = time.time()       \n",
    "            time_taken = end_time - start_time\n",
    "            timer += time_taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
