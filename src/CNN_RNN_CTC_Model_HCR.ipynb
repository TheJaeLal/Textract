{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "from helper import create_batches\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import shelve\n",
    "import joblib\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "\n",
    "#Cuz the file is inside 'code' directory\n",
    "mount_point = \"../\"\n",
    "\n",
    "with shelve.open(mount_point+'IAM_Data') as shelf:\n",
    "    vocabulary = shelf['chars']\n",
    "    list_of_images = shelf['list_of_images']\n",
    "    image_labels = shelf['image_labels']\n",
    "    \n",
    "# image_arrays = joblib.load(mount_point+'image_arrays')\n",
    "\n",
    "#List_images ko sort karo\n",
    "# list_of_images.sort()\n",
    "\n",
    "#Convert vocabulary to list\n",
    "vocabulary = list(vocabulary)\n",
    "#Sort so as to have the same ordering every time..\n",
    "vocabulary.sort()\n",
    "vocabulary.append(\"<Blank>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1000 --> Test\n",
    "#13000 --> Train\n",
    "#94 --> Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Model parameters\n",
    "img_height = 104\n",
    "img_width = 688\n",
    "vocab_size = len(vocabulary)\n",
    "\n",
    "#Common Hyper Parameters\n",
    "alpha = 0.0001\n",
    "epochs = 50\n",
    "\n",
    "#Should be proportional to the number of Images\n",
    "#should be divisible by 13000\n",
    "batch_size = 200 \n",
    "\n",
    "#Conv_net Params\n",
    "filter_size_1 = 5\n",
    "filter_size_2 = 3\n",
    "filter_size_3 = 3\n",
    "filter_size_4 = 3\n",
    "filter_size_5 = 1\n",
    "\n",
    "#Number of filters in each convolution layer\n",
    "num_conv1,num_conv2,num_conv3,num_conv4,num_conv5 = (20,50,100,200,400)\n",
    "\n",
    "#LSTM Params\n",
    "rnn_hidden_units = 200\n",
    "rnn_layers = 5\n",
    "\n",
    "#FC_Params\n",
    "#hidden layer should be two times vocabulary intuitively\n",
    "fc_input_units,fc_hidden_units,fc_output_units = (2*rnn_hidden_units, 2*vocab_size, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 5\n",
      "Tensor(\"bidirectional_rnn/fw/fw/transpose_1:0\", shape=(?, 145, 200), dtype=float32) Tensor(\"ReverseV2:0\", shape=(?, 145, 200), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# with tf.device('/gpu:0'):\n",
    "\n",
    "#Weights Initializer\n",
    "fc_initializer = tf.contrib.layers.xavier_initializer()\n",
    "conv_initializer = tf.contrib.layers.xavier_initializer_conv2d()\n",
    "\n",
    "#Weights for convolution layer\n",
    "# -> filter_size = 5 so filter = (5 x 5)\n",
    "#-> input_channels or (channels_in_image) = 1 \n",
    "#-> output_channels or (num_of_filters) = num_conv1\n",
    "\n",
    "wconv1_shape = [filter_size_1,filter_size_1,1,num_conv1]\n",
    "wconv2_shape = [filter_size_2,filter_size_2,num_conv1,num_conv2]\n",
    "wconv3_shape = [filter_size_3,filter_size_3,num_conv2,num_conv3]\n",
    "wconv4_shape = [filter_size_4,filter_size_4,num_conv3,num_conv4]\n",
    "wconv5_shape = [filter_size_5,filter_size_5,num_conv4,num_conv5]\n",
    "\n",
    "\n",
    "wfc1_shape = [fc_input_units, fc_hidden_units]\n",
    "wfc2_shape = [fc_hidden_units, fc_output_units]\n",
    "\n",
    "\n",
    "#Biases for conv_layer (single value, thus shape is empty tensor [])\n",
    "bconv_shape = []\n",
    "\n",
    "#Biases for fc layer (Batch_norm)\n",
    "bfc1_shape = [fc_hidden_units]\n",
    "bfc2_shape = [fc_output_units]\n",
    "\n",
    "#Initialize weights \n",
    "wconv1 = tf.Variable(conv_initializer(wconv1_shape))\n",
    "wconv2 = tf.Variable(conv_initializer(wconv2_shape))\n",
    "wconv3 = tf.Variable(conv_initializer(wconv3_shape))\n",
    "wconv4 = tf.Variable(conv_initializer(wconv4_shape))\n",
    "wconv5 = tf.Variable(conv_initializer(wconv5_shape))\n",
    "\n",
    "wfc1 = tf.Variable(fc_initializer(wfc1_shape))\n",
    "wfc2 = tf.Variable(fc_initializer(wfc2_shape))\n",
    "\n",
    "#Intialize biases\n",
    "bconv1 = tf.Variable(tf.zeros(bconv_shape))\n",
    "bconv2 = tf.Variable(tf.zeros(bconv_shape))\n",
    "bconv3 = tf.Variable(tf.zeros(bconv_shape))\n",
    "bconv4 = tf.Variable(tf.zeros(bconv_shape))\n",
    "bconv5 = tf.Variable(tf.zeros(bconv_shape))\n",
    "\n",
    "bfc1 = tf.Variable(tf.zeros(bfc1_shape))\n",
    "bfc2 = tf.Variable(tf.zeros(bfc2_shape))\n",
    "\n",
    "\n",
    "#Model\n",
    "#----------------------------------------------------------------------------#\n",
    "\n",
    "#Input Image\n",
    "inputs = tf.placeholder(tf.float32,shape=[None,img_height,img_width])\n",
    "\n",
    "\n",
    "X = tf.reshape(inputs,(-1,img_height,img_width,1))\n",
    "\n",
    "#-------------------Convolution-----------------------#\n",
    "#1st Convolutional Layer\n",
    "conv1 = tf.nn.conv2d(input=X,filter=wconv1,padding='SAME',strides=[1,1,1,1]) + bconv1\n",
    "conv1 = tf.nn.relu(conv1)\n",
    "\n",
    "#1st Pooling layer\n",
    "pool1 = tf.nn.max_pool(conv1,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "\n",
    "#2nd Convolutional Layer\n",
    "conv2 = tf.nn.conv2d(input=pool1,filter=wconv2,padding='SAME',strides=[1,1,1,1]) + bconv2\n",
    "conv2 = tf.nn.relu(conv2)\n",
    "\n",
    "#2nd Pooling Layer\n",
    "pool2 = tf.nn.max_pool(conv2,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "\n",
    "#3rd Convolutional Layer\n",
    "conv3 = tf.nn.conv2d(input=pool2,filter=wconv3,padding='SAME',strides=[1,1,1,1]) + bconv3\n",
    "conv3 = tf.nn.relu(conv3)\n",
    "\n",
    "#3rd Pooling Layer\n",
    "pool3 = tf.nn.max_pool(conv3,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "\n",
    "#4th Convolutional Layer\n",
    "conv4 = tf.nn.conv2d(input=pool3,filter=wconv4,padding='SAME',strides=[1,1,1,1]) + bconv4\n",
    "conv4 = tf.nn.relu(conv4)\n",
    "\n",
    "#4th Pooling Layer\n",
    "pool4 = tf.nn.max_pool(conv4,ksize=[1,3,3,1],strides=[1,3,3,1],padding='SAME')\n",
    "\n",
    "#5th Convolutional Layer\n",
    "conv5 = tf.nn.conv2d(input=pool4,filter=wconv5,padding='SAME',strides=[1,1,1,1]) + bconv5\n",
    "conv5 = tf.nn.relu(conv5)\n",
    "\n",
    "#--------All right upto here------------#\n",
    "conv_out_height, conv_out_width = (int(math.ceil(img_height/(2**3 * 3))),int(math.ceil(img_width/(2**3 * 3))))\n",
    "print(conv_out_width,conv_out_height)\n",
    "\n",
    "#----------------LSTM--------------------------#\n",
    "#Treat a single pixel from each filter or feature map as an individual feature\n",
    "#So number of features  = num_conv4 filters or feature maps\n",
    "#length_of_sequence = width * height of the output from conv3 \n",
    "\n",
    "lstm_inputs = tf.reshape(conv5,(-1,conv_out_height*conv_out_width,num_conv5))\n",
    "\n",
    "# lstm_inputs = tf.reshape(pool4,(-1,conv_out_width,conv_out_height*num_conv4))\n",
    "\n",
    "#Number of time_steps to unroll for..\n",
    "seq_len = conv_out_height * conv_out_width\n",
    "\n",
    "#So that we can use different batch size during testing...\n",
    "time_steps = tf.placeholder(tf.int32,shape = [None])\n",
    "\n",
    "# seq_len = conv_out_width\n",
    "\n",
    "targets = tf.sparse_placeholder(tf.int32,name='targets')\n",
    "\n",
    "dropout_lstm = tf.placeholder(tf.float32,shape=[])\n",
    "\n",
    "\n",
    "# # RNN Cells forward\n",
    "# cell_fw = tf.contrib.rnn.LSTMCell(rnn_hidden_units,initializer=fc_initializer)\n",
    "# # cells_fw = [tf.contrib.rnn.LSTMCell(rnn_hidden_units,initializer=fc_initializer) for _ in range(rnn_layers)]\n",
    "# cell_fw = tf.contrib.rnn.DropoutWrapper(cell_fw,output_keep_prob=dropout_lstm,dtype=tf.float32)\n",
    "\n",
    "\n",
    "# # RNN Cells backward\n",
    "# cell_bw = tf.contrib.rnn.LSTMCell(rnn_hidden_units,initializer=fc_initializer)\n",
    "# cell_bw = tf.contrib.rnn.DropoutWrapper(cell_bw,input_keep_prob=dropout_lstm,output_keep_prob=dropout_lstm,dtype=tf.float32)\n",
    "\n",
    "# cells_bw = [tf.contrib.rnn.LSTMCell(rnn_hidden_units,initializer=fc_initializer) for _ in range(rnn_layers)]\n",
    "\n",
    "\n",
    "list_cells_fw = []\n",
    "for _ in range(rnn_layers):\n",
    "    cell_fw = tf.contrib.rnn.LSTMCell(rnn_hidden_units,initializer=fc_initializer)\n",
    "    drop_fw = tf.contrib.rnn.DropoutWrapper(cell_fw,output_keep_prob=dropout_lstm,dtype=tf.float32)\n",
    "    list_cells_fw.append(cell_fw)\n",
    "\n",
    "\n",
    "list_cells_bw = []\n",
    "for _ in range(rnn_layers):\n",
    "    cell_bw = tf.contrib.rnn.LSTMCell(rnn_hidden_units,initializer=fc_initializer)\n",
    "    drop_bw = tf.contrib.rnn.DropoutWrapper(cell_bw,output_keep_prob=dropout_lstm,dtype=tf.float32)\n",
    "    list_cells_bw.append(cell_bw)\n",
    "\n",
    "cells_fw = tf.contrib.rnn.MultiRNNCell(list_cells_fw)\n",
    "cells_bw = tf.contrib.rnn.MultiRNNCell(list_cells_bw)\n",
    "\n",
    "\n",
    "(outputs_fw,outputs_bw),_ = tf.nn.bidirectional_dynamic_rnn(cells_fw,cells_bw,lstm_inputs,dtype=tf.float32)\n",
    "# outputs,_,_ = tf.contrib.rnn.stack_bidirectional_dynamic_rnn(cells_fw,cells_bw,inputs = lstm_inputs,dtype=tf.float32)\n",
    "print(outputs_fw,outputs_bw)\n",
    "\n",
    "#Concatenate the output from both cells (forward and backward)\n",
    "blstm_outputs = tf.concat([outputs_fw,outputs_bw], 2)\n",
    "\n",
    "#flatten out all except the last dimension\n",
    "fc_inputs  = tf.reshape(blstm_outputs,[-1,2*rnn_hidden_units])\n",
    "\n",
    "#Feed into the fully connected layer\n",
    "#No activation cuz, the output of this layer is feeded into CTC Layer as logits\n",
    "\n",
    "dropout_fc = tf.placeholder(tf.float32,shape=[])\n",
    "\n",
    "fc_outputs_1 = tf.matmul(fc_inputs,wfc1) + bfc1\n",
    "fc_outputs_1 = tf.nn.dropout(fc_outputs_1,dropout_fc)\n",
    "\n",
    "fc_outputs_2 = tf.matmul(fc_outputs_1,wfc2) + bfc2\n",
    "fc_outputs_2 = tf.nn.dropout(fc_outputs_2,dropout_fc)\n",
    "\n",
    "#Reshape back to batch_size, seq_len,vocab_size\n",
    "logits = tf.reshape(fc_outputs_2,[-1,seq_len,vocab_size])\n",
    "\n",
    "#convert them to time major\n",
    "logits = tf.transpose(logits,[1,0,2])\n",
    "\n",
    "#Calculate loss\n",
    "loss = tf.nn.ctc_loss(targets, logits, time_steps)\n",
    "cost = tf.reduce_mean(loss)\n",
    "\n",
    "#Optimize\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=alpha)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# CTC decoder.\n",
    "\n",
    "#decoded, log_prob = tf.nn.ctc_greedy_decoder(logits, seq_len)\n",
    "decoded, log_prob = tf.nn.ctc_greedy_decoder(logits, time_steps)\n",
    "\n",
    "label_error_rate = tf.reduce_mean(tf.edit_distance(tf.cast(decoded[0], tf.int32),\n",
    "                                                   targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 29)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_out_height,conv_out_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Placeholder_3:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout_fc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save my MoDel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver(max_to_keep=None)\n",
    "\n",
    "random.shuffle(list_of_images)\n",
    "train_size = 13000\n",
    "test_size = 1000\n",
    "valid_size = 94\n",
    "\n",
    "training_list = list_of_images[:train_size]\n",
    "testing_list = list_of_images[train_size:train_size+test_size]\n",
    "validation_list = list_of_images[train_size+test_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13000, 1000, 94)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_list),len(testing_list),len(validation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_batches_x,test_batches_y = create_batches(len(testing_list),testing_list,image_arrays,image_labels,vocabulary)\n",
    "valid_batches_x,valid_batches_y = create_batches(len(validation_list),validation_list,image_arrays,image_labels,vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,141.033752,0.98,0.98,95.18699598312378\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_0 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "1,141.087387,0.97,0.98,92.12399196624756\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_1 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "2,137.163635,0.97,0.98,92.43513774871826\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_2 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "3,138.639252,0.98,0.98,90.83072066307068\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_3 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "4,135.670486,0.97,0.98,92.41278791427612\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_4 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "5,136.670044,0.98,0.98,90.6999671459198\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_5 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "6,134.577682,0.97,0.98,92.70359778404236\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_6 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "7,135.103989,0.97,0.98,90.87947964668274\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_7 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "8,138.250595,0.98,0.98,91.33041310310364\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_8 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "9,138.524460,0.98,0.98,90.30147743225098\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_9 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "10,138.731705,0.97,0.98,90.95124983787537\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_10 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "11,140.178619,0.98,0.98,90.82617259025574\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_11 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "12,133.986084,0.97,0.98,90.68421077728271\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_12 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "13,141.955734,0.98,0.98,90.86183834075928\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_13 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "14,135.674011,0.98,0.98,90.8841712474823\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_14 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "15,140.169510,0.98,0.98,91.39570212364197\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_15 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "16,134.224152,0.97,0.98,90.68186640739441\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_16 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "17,137.161499,0.98,0.98,90.37731647491455\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_17 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "18,136.159622,0.98,0.98,90.14029431343079\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_18 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "19,136.493668,0.98,0.98,90.3103334903717\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_19 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "20,136.359680,0.98,0.98,90.23500037193298\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_20 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "21,131.357407,0.92,0.93,90.50250434875488\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_21 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "22,135.529938,0.92,0.92,90.47103118896484\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_22 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "23,131.547241,0.90,0.90,90.14824604988098\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_23 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "24,127.750282,0.91,0.92,89.85955810546875\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_24 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "25,129.338730,0.92,0.92,90.21245241165161\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_25 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "26,134.348251,0.91,0.91,89.87753248214722\n",
      "\n",
      "INFO:tensorflow:../model/200_5_Lines_RNN_26 is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-4614054a231c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m#Create new training_batches..\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mtrain_batches_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_batches_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_arrays\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m#Checkpoint after every 5 epochs..\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/HCR/code/helper.py\u001b[0m in \u001b[0;36mcreate_batches\u001b[0;34m(batch_size, training_list, image_arrays, image_labels, vocabulary)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_arrays\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_batch_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_arrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_batch_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_batch_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_arrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/HCR/code/helper.py\u001b[0m in \u001b[0;36m_batch_x\u001b[0;34m(batch_size, training_list, image_arrays)\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;31m# then current_batch --> (height,width,2) and so, on until you get\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;31m#current_batch --> (height,width,batch_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0mcurrent_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnext_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0mbatches_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/numpy/lib/shape_base.py\u001b[0m in \u001b[0;36mdstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m     \"\"\"\n\u001b[0;32m--> 421\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matleast_3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_replace_zero_by_x_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_arys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    #Set Checkpoints and Timer\n",
    "    checkpoint = False\n",
    "    timer = 0\n",
    "    \n",
    "    for e in range(epochs): \n",
    "        start_time = time.time()\n",
    "        \n",
    "        #Shuffle the training_list\n",
    "        random.shuffle(training_list)\n",
    "        \n",
    "        #Create new training_batches..\n",
    "        train_batches_x,train_batches_y = create_batches(batch_size,training_list,image_arrays,image_labels,vocabulary)\n",
    "\n",
    "        #Checkpoint after every 5 epochs..\n",
    "        if (e%1)==0:\n",
    "            checkpoint = True\n",
    "           \n",
    "        total_cost = 0.0\n",
    "        total_ler = 0.0\n",
    "        #Iterate through all images in a single epoch...\n",
    "        for b in range(len(train_batches_x)):\n",
    "            \n",
    "            #Before feeding x reshape it as (batch_size,width,height)\n",
    "            feed_train = {\n",
    "                    inputs:train_batches_x[b].transpose([2,0,1]),targets:train_batches_y[b],\n",
    "                    time_steps:np.array([seq_len]*batch_size),\n",
    "                    dropout_fc:np.array(1.0),dropout_lstm:np.array(1.0)\n",
    "                   }\n",
    "\n",
    "            _,cost_val,train_ler_val = sess.run([train,cost,label_error_rate],feed_dict=feed_train)\n",
    "            \n",
    "            total_cost+=cost_val\n",
    "            total_ler+=train_ler_val\n",
    "            \n",
    "          # Finished batches...  \n",
    "#         if checkpoint:\n",
    "#             #Calculate cost and ler of last train batch\n",
    "#             last_cost,train_ler = sess.run([cost,label_error_rate],feed_dict=feed_train)\n",
    "\n",
    "        avg_cost = total_cost/len(train_batches_x) \n",
    "        avg_ler = train_ler/len(train_batches_x)\n",
    "        \n",
    "        #After iterating through all batches..\n",
    "        valid_batch_size = len(validation_list)\n",
    "\n",
    "        feed_valid = {\n",
    "            inputs:valid_batches_x[0].transpose([2,0,1]),targets:valid_batches_y[0],\n",
    "            time_steps:np.array([seq_len]*valid_batch_size),\n",
    "            dropout_fc:np.array(1.0),dropout_lstm:np.array(1.0)\n",
    "           }\n",
    "\n",
    "        #Evaluate the model, and store every 5 epochs...\n",
    "        if checkpoint:\n",
    "            #Accuracy on valid_data\n",
    "            test_ler = sess.run(label_error_rate,feed_dict=feed_valid)                \n",
    "\n",
    "            end_time = time.time()       \n",
    "            time_taken = end_time - start_time\n",
    "            timer += time_taken\n",
    "     \n",
    "            print(\"{},{:.6f},{:.2f},{:.2f},{}\\n\".format(e,avg_cost,avg_ler,test_ler,timer))\n",
    "\n",
    "            with open('progress.csv','a') as f:\n",
    "                f.write(\"{},{:.6f},{:.2f},{:.2f},{}\\n\".format(e,avg_cost,avg_ler,test_ler,timer))\n",
    "\n",
    "            #Save the model\n",
    "            saver.save(sess,'../model/200_5_Lines_RNN_'+str(e))\n",
    "\n",
    "            #Reset the checkpoint-flag and timer\n",
    "            checkpoint = False\n",
    "            timer = 0\n",
    "        \n",
    "        else:\n",
    "            end_time = time.time()       \n",
    "            time_taken = end_time - start_time\n",
    "            timer += time_taken"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
